# microservices-with-react-and-nodejs

> Build, deploy, and scale a Microservices built with Node, React, Docker and Kubernetes.

## Menu

1. Fundamental Ideas Around Microservices
2. A Mini-Microservices App
3. Running Services with Docker
4. Orchestrating Collections of Services with Kubernetes
5. Architecture of Multi-Service Apps
6. Leveraging a Cloud Environment for Development
7. Response Normalization Strategies
8. Database Management and Modeling
9. Authentication Strategies and Options
10. Testing Isolated Microservices
11. Integrating a Server-Side-Rendered React App
12. Code Sharing and Reuse Between Services
13. Create-Read-Update-Destroy Server Setup
14. NATS Streaming Server - An Event Bus Implementation
15. Connecting to NATS in a Node JS World
16. Managing a NATS Client
17. Cross-Service Data Replication In Action
18. Understanding Event Flow
19. Listening for Events and Handling Concurrency Issues
20. Worker Services
21. Handling Payments
22. Back to the Client
23. CI/CD

## Notes

![nats1](images/nats.jpg)

## Chapter

### 01-å¾®æœåŠ¡åŸºç¡€

- æå¾®æœåŠ¡ä¹‹å‰ï¼Œä¸å¾—ä¸å…ˆçœ‹çœ‹ `å•ä½“åº”ç”¨`

![001](images/001.png)
![002](images/002.png)
![003](images/003.png)

- Each service gets its own databse (if it needs one)

![003](images/ch01/003.png)

- With microservices, we store and access data sort of strange way (æœçœŸæœ‰ç‚¹å¥‡æ€ª ğŸ˜‚)

- Services will never, ever reach into another services database

![004](images/ch01/004.png)

![004](images/004.png)

> ä¸€ç›´æ²¡æƒ³å¥½æ€ä¹ˆè§£é‡Š A æœåŠ¡è°ƒ B æœåŠ¡çš„æ•°æ®åº“çš„å¼Šç«¯ï¼ŒåŸæ¥å¦‚æ­¤ã€‚

#### Why Database-Per-Service

- We want each service to run independently of other services
- Database sechema/structure might change unexpectedly
- Some services migth function more efficiently with different types of DB's (sql vs nosql)
  - æŸäº›æœåŠ¡è·‘åœ¨ä¸é€šç±»å‹çš„æ•°æ®åº“ä¸Šèƒ½æœ‰æ›´é«˜æ•ˆçš„è¿è¡Œæ•ˆç‡

#### Quiz - Data in Microservices

> è€å“¥å‡ºä¸ªé¢˜ç›®éƒ½é‚£ä¹ˆä¸“ä¸š ğŸ‚ ğŸƒ ğŸ„ ğŸ¦

- ğŸ‘€ Creating one database per service seems like a waste! Why do we create one database per services?

  - âœ… We want every service to be able to act independently whitout depending on any other service
  - âœ… If each service has its own database, we can optimize what type of database we pick for a service
  - âœ… A single databse shared between many services would be a single point of failure, which would limit the reliability of our app

- ğŸ‘€ What is the #1 challenge in microservices?
  - âœ… Managing data between different services
  - âŒ Implementing monitoring and logging for services written in different languages
  - âŒ Deploying two services at the same time

#### æœåŠ¡é—´é€šä¿¡

![008](images/ch01/007.png)

- åŒæ­¥é€šä¿¡

ä¸¾ä¸ªä¾‹å­ï¼š

![005](images/005.png)

- åŒæ­¥é€šä¿¡è¦ç‚¹
  - Conceptually easy to understand! (æ¦‚å¿µå¾ˆç®€å•)
  - Service D won't need a databse! (æœåŠ¡å™¨ä¸éœ€è¦ä¾èµ–æ•°æ®åº“)
  - introduces a dependency between services (å¼•å…¥ä¸€ä¸ªä¾èµ–åœ¨å„æœåŠ¡ä¹‹é—´ï¼è€Œä¸æ˜¯ A å»è°ƒ Bã€Cï¼Œæˆ‘ä»¥å‰çœŸæ˜¯è¿™ä¹ˆå¹²çš„)
  - If any inter-service request fails, the overall request fails (å…¶ä¸­ä»»ä½•ä¸€ä¸ªå­æœåŠ¡å‡ºé”™ï¼Œåˆ™æ•´ä¸ªä¸šåŠ¡é“¾ä¸Šçš„è¯·æ±‚ä¹Ÿå‡ºé”™)
  - The entire request is only as fast as the slowest request (ä¸€ä¸ªå®Œæ•´çš„è¯·æ±‚æ˜¯å¦å®Œæˆå¾—çœ‹æœ€æ…¢çš„å“ªä¸€ä¸ªå­è¯·æ±‚)
  - Can easilty intoduce webs of requests (å¥½å¤„ï¼Ÿè½»æ¾æ¥å…¥å„ç§ web è¯·æ±‚)

ä¸¾ä¸ªåŒæ­¥é€šä¿¡çš„ä¾‹å­ ğŸŒ°

![006](images/006.png)

![010](images/ch01/010.png)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¦æ˜¯å„ä¸ªæœåŠ¡ç”¨åŒæ­¥é€šä¿¡ï¼Œå¼€å‘åˆ°åæœŸçœŸçš„å¦‚ä¹±éº»ä¸€æŠŠéš¾ç¼ äº†ï¼Œå¿«ç‚¹ç¥­å‡º â€œå¼‚æ­¥é€šä¿¡â€ å§ã€‚

![007](images/007.png)

ä¸ºæ¯ä¸ªæœåŠ¡é…ç½®ç‹¬ç«‹æ•°æ®åº“ï¼Œå¹¶ä¸”ç”¨å¼‚æ­¥é€šä¿¡è¿™ä¹Ÿçš„è®¾è®¡æ¨¡å¼çœ‹ä¸Šå»è¯¡å¼‚åˆä½æ¶ˆï¼

![008](images/008.png)

- å¼‚æ­¥é€šä¿¡è¦ç‚¹
  - ğŸ‘ Service D has zero dependencies on other services!
  - ğŸ‘ Service D will be extremely fast!
  - ğŸ‘ Data duplication - paying for extra storage + extra DB
  - ğŸ‘ Harder to understand

### 02-mini-microservices-system

- client
- posts
  - `yarn add express cors axios nodemon`
- comments
  - `yarn add express cors axios nodemon`

![009](images/009.png)

> åœ¨å•ä½“åº”ç”¨ä¸­ï¼Œæ¯•ç«Ÿåœ¨ä¸€ä¸ªæ•°æ®åº“é‡Œçš„ä¸åŒçš„è¡¨ï¼Œå¾ˆå¥½è§£å†³ï¼

![010](images/010.png)

> ä½†åœ¨å¾®æœåŠ¡ä¸­ï¼Œæ€ä¹ˆè§£å†³å‘¢ï¼Ÿ

![011](images/011.png)

åŒæ­¥æ–¹æ¡ˆï¼šæ„æ€è¿˜æ˜¯æ¥ä¸ªåŒæ­¥é€šä¿¡äº†ã€‚

![012](images/012.png)

#### å¼‚æ­¥æ–¹æ¡ˆ

- ğŸ‘€ Wait, so you are saying we need to create a new service every time we need to join some data ?!?!?!
  - Absolutely not! In reality, might not even have posts and comments in separate services in the first place

#### Event Bus

- Many different implementations. RabbitMQ, Kafka, NATS...
- Receives events, publishes them to listeners
- Many different subtle features that make async communication way easier or way harder
  - è®¸å¤šä¸åŒä¸”å¾®å¦™çš„åŠŸèƒ½å¯èƒ½ä¼šä½¿å¾—å¼‚æ­¥é€šä¿¡å˜å¾—æ›´å®¹æ˜“æˆ–æ›´éš¾
- We are going to build out own event bus using Express. It will not implement the vast majority of features a normal bus has.
  - `mini` é˜¶æ®µæˆ‘ä»¬ç”¨ `Express` å»ºè®®æ¨¡æ‹Ÿäº‹ä»¶æ€»çº¿ï¼Œåé¢å†ç”¨æ­£å„¿å…«ç»çš„
  - æ˜¯çš„ï¼Œæ¨¡æ‹Ÿé˜¶æ®µä½¿ç”¨ `Express` å‡æŠŠæ„æ€çš„è°ƒåº¦ä¸‹è€Œå·²
  - åŸæ¥ Event Bus æ˜¯è°ƒåº¦å™¨çš„ä½œç”¨ï¼Œå¦‚æœæ¢ä¸Šæ¶ˆæ¯é˜Ÿåˆ—å°±æŠŠåŒæ­¥è°ƒåº¦è½¬æ¢æˆå¼‚æ­¥è¢«åŠ¨æ‰§è¡Œ
- Yes, for our next app we will use a production grade, open source event bus

![012x](images/012x.png)

> åœ¨ mini ç³»ç»Ÿé‡Œï¼Œæ‰€æœ‰æœåŠ¡éƒ½ç›‘å¬ç€ Event Bus çš„æ¶ˆæ¯ï¼Œå°±æ˜¯è‡ªå·±æœåŠ¡å‘ç”Ÿçš„ä¸€ä»¶äº‹ä¸”æ˜¯è‡ªå·±å‘å‡ºæ¥çš„ï¼Œä¹Ÿä¼šæ”¶åˆ° `æ€»çº¿` çš„å›é¦ˆã€‚

ç‹¬ç«‹ä¸€ä¸ª Query-Service å‡ºæ¥æœ‰åˆ©æœ‰å¼Šå§

- åˆ©ï¼šå‡å°‘äº†æ•°æ®åº“æŸ¥è¯¢æ¬¡æ•°
- å¼Šï¼šå¢åŠ äº‹åŠ¡ã€å¢åŠ æ•°æ®ä¸ä¸€è‡´çš„å¯èƒ½æ€§ï¼Œå®æ—¶æ€§è¦æ±‚è¾ƒé«˜çš„ç³»ç»Ÿä¸åˆé€‚
- è¿™åº”è¯¥ç®—æ˜¯ CQRS å‘½ä»¤æŸ¥è¯¢èŒè´£åˆ†ç¦»
- ä¹Ÿå¯ä»¥æ˜¯ç®€å•çš„èµ„æºåˆå¹¶

![013x](images/013x.jpeg)

æ–°å¢åŠŸèƒ½ï¼šè¯„è®ºå®¡æ ¸æœºåˆ¶

![014](images/014.png)

![015](images/015.png)

- The query service is about presentation logic
- It is join ing two resources right now (posts and comments), but it might join 10!
- Does it make sense for a presentation service to understand how to process a very precise update?
- Query-Service åªå’Œå±•ç¤ºæœ‰å…³ï¼Œæ•°æ®è·Ÿæ–°å’Œä»–æ²¡å…³ç³»ï¼Œæ‰€è¯´æ–¹æ¡ˆäºŒä¸å¯è¡Œ
- è€Œä¸”æœªæ¥éšç€åŠŸèƒ½è¶Šæ¥è¶Šå¤šï¼Œä»£ç ä¼šè¶Šæ¥è¶Šå†—ä½™ï¼å®ƒè¦å¤„ç†çš„äº‹ä»¶å¤ªå¤šï¼Œå…¶å®æˆ‘ä»¬åªéœ€è¦è¦ query-service åªå…³æ³¨ä¸€ä»¶äº‹ `CommentUpdated` å³å¯

![016](images/016.png)

![017](images/017.png)

å¦‚ä½•å¤„ç†äº‹ä»¶ä¸¢å¤±çš„æƒ…å†µ

![018](images/018.png)

![021](images/021.png)

æˆ‘ä»¬è®¾æƒ³è¿™ä¹ˆä¸€ä¸ªåœºæ™¯ï¼šå¦‚æœ Query æˆ–è€… Moderation æœåŠ¡å¤±æ•ˆï¼Œåˆ™ Comments æœåŠ¡çš„æ•°æ®æ˜¯ä¸€å®šå˜äº†ï¼Œä½† Query æœåŠ¡çš„æ•°æ®æ²¡å˜ï¼Œè¿™å°±æ˜¯æ•°æ®ä¸ä¸€è‡´é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯ä¸ªäº‹åŠ¡çš„ä¸å®Œæ•´æ€§ï¼Œé‚£è¯¥æ€ä¹ˆè§£å†³æ•°æ®å­˜å‚¨çš„ä¸ä¸€è‡´æ€§é—®é¢˜å‘¢ï¼Ÿ

- å¦‚ä¸‹æœ‰ä¸‰ç§æ–¹å¼ï¼š
  - ç¬¬ä¸€ç§ `â€œåŒæ­¥è¯·æ±‚â€`ï¼šæ¯æ¬¡æ¥è¯·æ±‚äº†ï¼Œä¸¤è¾¹æ•°æ®æºéƒ½é—®ä¸€éï¼ğŸ˜‚
  - ç¬¬äºŒç§ `â€œç›´è¿æ•°æ®åº“â€`ï¼šä¸è¯´äº†ï¼Œä¸å¯èƒ½ï¼
  - ç¬¬ä¸‰ç§ï¼š`â€œå­˜å‚¨äº‹ä»¶æ¶ˆæ¯â€`ï¼šç›®å‰æ¯”è¾ƒåˆé€‚çš„æ–¹æ¡ˆï¼Œè¿™ä¸ªæ–¹æ¡ˆçš„ç¡®æ˜¯ CQRSï¼
    - è€å“¥ä¸€ç›´åœ¨ç»™ NATS ä½œé“ºå«ï¼ŒåŸç”Ÿè‡ªå¸¦è§£å†³æ–¹æ¡ˆå˜›

![019](images/019.png)

![020](images/020.png)

![022](images/022.png)

- è®©æ€»çº¿æŠŠé”™è¯¯çš„äº‹ä»¶å…ˆå­˜ä¸‹æ¥ï¼Œç­‰é‚£ä¸ªæ¶ˆè´¹æ¶ˆæ¯å¤±è´¥çš„æœåŠ¡é‡æ–°ä¸Šçº¿äº†ï¼Œå†å‘é€å‡ºæ¥ã€‚
- NATS åŸç”ŸåŠŸèƒ½ï¼Œè€Œä¸”è¿˜å¸¦åºå·çš„
- ä¹Ÿä¸æ˜¯åªå­˜å‚¨æœªæ¶ˆè´¹çš„æ¶ˆæ¯ï¼Œè€Œæ˜¯å…¨éƒ¨éƒ½å­˜å‚¨èµ·æ¥

![023](images/023.png)

å¼±å¼±åœ°æ€»ç»“ä¸‹æˆ‘ä»¬ `mini-system` CQRSï¼š

- é¦–å…ˆ Event Bus å­˜å‚¨æ‰€æœ‰ Event
- ç„¶åæ¯ä¸ªæ‰€ä¾èµ–æœåŠ¡çš„æ¯æ¬¡é‡å¯éƒ½æ¶ˆè´¹ä¸€éæ‰€æœ‰æ—§çš„äº‹åŠ¡(æ‰€æœ‰)
- æœ€åå¼€å§‹ç›‘å¬å¤„ç†æ–°äº‹ç‰©

è¿™æ ·çš„å¥½å¤„å°±æ˜¯ï¼š

- Query Service æŒ‚äº†ï¼Œæˆ‘ Posts ç…§æ ·èƒ½å†™
- Moderation Service æŒ‚äº†ï¼Œæˆ‘æŸ¥è¯¢å’Œä¸‹å…¥ç…§æ · OK
- æˆ‘ Comments Service æŒ‚äº†ï¼Œæˆ‘æŸ¥è¯¢ç…§æ ·å¯ä»¥

> ğŸ‚ ğŸ„ ğŸ¦ ğŸ¦¬ ğŸƒ

### 03-Running Services with Docker

![024](images/024.png)

![025](images/025.png)

![026](images/026.png)

Why Docker ?

- running our app right now makes big assumptions about out environment
- running our app requires precise knowledge of how to start it (npm start)
- Docker solves both these issues. Containers wrap up everything that is needed for a program + how to start run run it

Why k8s ?

- K8s is a tool for running a bunch of different containers
- We give it some configuration to describe how we want our containers to rn and interact with each other

![027](images/027.png)

![028](images/028.png)

> éƒ½æ˜¯äº›åŸºæ“ï¼

![029](images/029.png)

![030](images/030.png)

![031](images/031.png)

![032](images/032.png)

> `kubectl apply -f posts.yaml`

![033](images/033.png)

![034](images/034.png)

![036](images/036.png)

æ–¹æ³•ä¸€ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶é‡Œçš„ç‰ˆæœ¬å·ï¼Œæ›´æ–°`deployment`

> æ­¤æ–¹æ³•ä¸å¯è¡Œï¼Œè¿œç¨‹æœåŠ¡å™¨ä¸€å¤šï¼Œæ”¹çš„é…ç½®æ–‡ä»¶ä¹Ÿå¤šï¼Œéº»çƒ¦ï¼

![035](images/035.png)

æ–¹æ³•äºŒï¼šä½¿ç”¨`latest`æ ‡ç­¾æ›´å¥½ï¼Œå…¶æ­¥éª¤å¦‚ä¸‹ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: posts-depl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: posts
  template:
    metadata:
      labels:
        app: posts
    spec:
      containers:
        - name: posts
          image: registry.cn-shenzhen.aliyuncs.com/444/m-blog-posts:latest
```

- 1.åœ¨ `deployment` æè¿°æ—¶ï¼Œå®¹å™¨çš„é•œåƒä¸€å®šè¦ç”¨ `latest` æ ‡ç­¾
- 2.ä¿®æ”¹ä»£ç 
- 3.åˆ¶ä½œæ–°ç‰ˆæœ¬é•œåƒ
- 4.æ¨é€åˆ°é•œåƒæœåŠ¡: `docker-hub`
- 5. é‡å¯ `deployment`ï¼Œæ­¤æ—¶ä»–ä¼šæ¯”è¾ƒ image çš„å€¼ï¼Œçœ‹æœ‰æ–°çš„æ²¡ï¼Œæœ‰å°±æ‹‰å–é‡æ–°éƒ¨ç½²
  - `kubectl rollout restart deployment [depl_name]`

![037](images/037.png)

- `Cluster IP` å–ä¸ªå·è¾“å…¥çš„ url è®© pord å¯ä»¥å† k8s çš„é›†ç¾¤å†…éƒ¨è¢«è®¿é—®ï¼
- `Node Port` è®© pod å¯ä»¥è¢«â€œå¤–ç½‘è®¿é—®â€ï¼Œä½†éƒ½æ˜¯ç”¨äºå¼€å‘æµ‹è¯•
- `Load Balancer` è¿™æ‰æ˜¯æ­£ç¡®çš„è®© pod è¢«è®¿é—®çš„æ­£ç¡®æ–¹å¼ï¼Œç”Ÿäº§ç”¨
- `External Name` å–ä¸ªåˆ«å CNAME

```yaml
appVersion: v1
kind: Service
metadata:
  name: posts-serv
spec:
  type: NodePort
  selector:
    app: posts
  posts:
    - name: posts
      protocol: TCP
      port: 4000
      targetPort: 4000
```

![038](images/038.png)

> ç®€ç›´ç©æ­»äººï¼macOS+docker çš„ minikube ç½‘ç»œè®¿é—®æ˜¯ä¸ªå‘ï¼Œç©äº†ä¸ªä¸€ä¸ªåŠå°æ—¶ï¼Œæ¢ vm æ‰å¯ä»¥ï¼ç›´æ¥ä» 23 ç‚¹å‘åˆ° 1 ç‚¹å¤šï¼Œææ­»ï¼

```bash
$ minikube start --registry-mirror=https://registry.docker-cn.com --kubernetes-version=1.18.8 --driver=virtualbox

$ minikube ip
192.168.99.100

$ minikube service posts-srv --url
http://192.168.99.100:31557
```

#### ClusterIP çš„æ­£ç¡®ç”¨æ³•

![039](images/039.png)

Golas Moving Forward

- Build an `image` for the Event Bus
- `Push` the image to Docker Hub
- Create a `deployment` for Event Bus
- Create a `Cluster IP service` for Event Bus and Posts
- Wire it all up!

> æ€ä¹ˆçœ‹ `pod` æˆ– `depl` çš„ `clusterIP` å‘¢ï¼Ÿå…¶å®å°±æ˜¯ `k get services` ï¼Œç„¶åçœ‹ `name` å³å¯ï¼Œè¿™æ—¶æˆ‘ä»¬å°±å¯ä»¥åœ¨ `Cluster` é‡Œä½¿ç”¨é‚£ä¹ˆè®¿é—®åˆ°è¿™ä¸ª `pod`

Adding More Services

- For 'comments', 'query', 'moderation'...
- Update the URL's in each to reach out to the 'event-bus-srv'
- Build images + push them to docker hub
- Create a depolyment + clusterIP service for each
- Update the event-bus to once again send events to 'comments', 'query', 'moderation'

> é‚£ä¹ˆä¹…å¼€å§‹å†é€ å‰©ä½™æœåŠ¡ï¼Œè¿™ä¸‰ä¸ªæœåŠ¡å™¨éƒ½ä¾èµ–æ€»çº¿ï¼Œæ”¹èµ·æ¥ä¹Ÿç°å¸¸ç®€å•ï¼ŒçœŸçš„æœ‰ç‚¹æ„Ÿè§‰äº†ã€‚

![040](images/040.png)

> æŠŠå‰©ä½™æœåŠ¡æ•´å®Œï¼Œå¯åŠ¨ `query` æœåŠ¡åå‘ç°ï¼Œåˆ›å»ºå‰çš„äº‹åŠ¡ä¹Ÿ `åŒæ­¥`è¿‡æ¥äº†ï¼Œ`Event Store` ã€ `CQRS` çœŸå¿ƒä¸é”™ã€‚

```bash
~/git/microservices-with-react-and-nodejs/blog/posts on î‚  master! âŒš
$ k describe pod query-depl-77b8cc9684-hqhbr
Name:         query-depl-77b8cc9684-hqhbr
Namespace:    default
Priority:     0
Node:         minikube/192.168.99.100
Start Time:   Tue, 17 Aug 2021 15:38:45 +0800
Labels:       app=query
              pod-template-hash=77b8cc9684
Annotations:  <none>
Status:       Running
IP:           172.17.0.7
IPs:
  IP:           172.17.0.7
Controlled By:  ReplicaSet/query-depl-77b8cc9684
Containers:
  query:
    Container ID:   docker://e41ea415d2e24bb9fe5ce3a470ef9b37cefb359d588d159a3510c99f7d191057
    Image:          registry.cn-shenzhen.aliyuncs.com/444/m-blog-query:latest
    Image ID:       docker-pullable://registry.cn-shenzhen.aliyuncs.com/444/m-blog-query@sha256:2a4cd605c80df6c4f487836a2831a7dcdce26b1a4b693e936e7298695a665058
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 17 Aug 2021 15:38:50 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kt77w (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  default-token-kt77w:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-kt77w
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  7m52s  default-scheduler  Successfully assigned default/query-depl-77b8cc9684-hqhbr to minikube
  Normal  Pulling    7m51s  kubelet            Pulling image "registry.cn-shenzhen.aliyuncs.com/444/m-blog-query:latest"
  Normal  Pulled     7m47s  kubelet            Successfully pulled image "registry.cn-shenzhen.aliyuncs.com/444/m-blog-query:latest"
  Normal  Created    7m47s  kubelet            Created container query
  Normal  Started    7m47s  kubelet            Started container query
```

> çœ‹ä¸‹ `pod` çš„å¥åº·çŠ¶å†µ
>
> ç°åœ¨ docker çš„ `cli` å‘½ä»¤ä¹Ÿå’Œ `k8s` çš„é æ‹¢äº†ï¼Œä»¥åè¿›æ¥æ”¹æ‰åŸæ¥çš„ `docker-cli` ä¹ æƒ¯

#### å…³äºæ€ä¹ˆå¯¼å…¥æµé‡

![041](images/041.png)

æ–¹æ¡ˆä¸€ï¼šæ­¤æ–¹æ¡ˆè‚¯å®šä¸è¡Œã€‚è¦ç®¡ç†å¤šä¸ª NodePort çš„æœåŠ¡ï¼Œå†µä¸”å®ƒä¹Ÿæ‰›ä¸ä½ï¼Œåªèƒ½ç”¨æ¥å¼€å‘ã€‚å¯¹äº†è€Œä¸”è¿™ä¸ªç«¯å£å¤šæ•°æƒ…å†µæ˜¯éšæœºï¼Œä¹Ÿèƒ½æ‰‹åŠ¨å›ºå®šã€‚

![042](images/042.png)

- Load Balancer Serviceï¼šTells k8s to reach out to its provider and provision a load balancer. Gets traffic in to a single pod
- Ingress or Ingress Controller: A pod with a set of routing rules to distribute traffic to other services

![045](images/045.png)

#### ingress

> service æ—¶æœ‰è¯´äº†æš´éœ²äº† service çš„ä¸‰ç§æ–¹å¼ ClusterIPã€NodePort ä¸ LoadBalanceï¼Œè¿™å‡ ç§æ–¹å¼éƒ½æ˜¯åœ¨ service çš„ç»´åº¦æä¾›çš„ï¼Œservice çš„ä½œç”¨ä½“ç°åœ¨ä¸¤ä¸ªæ–¹é¢ï¼Œå¯¹é›†ç¾¤å†…éƒ¨ï¼Œå®ƒä¸æ–­è·Ÿè¸ª pod çš„å˜åŒ–ï¼Œæ›´æ–° endpoint ä¸­å¯¹åº” pod çš„å¯¹è±¡ï¼Œæä¾›äº† ip ä¸æ–­å˜åŒ–çš„ pod çš„æœåŠ¡å‘ç°æœºåˆ¶ï¼Œå¯¹é›†ç¾¤å¤–éƒ¨ï¼Œä»–ç±»ä¼¼è´Ÿè½½å‡è¡¡å™¨ï¼Œå¯ä»¥åœ¨é›†ç¾¤å†…å¤–éƒ¨å¯¹ pod è¿›è¡Œè®¿é—®ã€‚ä½†æ˜¯ï¼Œå•ç‹¬ç”¨ service æš´éœ²æœåŠ¡çš„æ–¹å¼ï¼Œåœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ä¸å¤ªåˆé€‚ï¼š
>
> 1.ClusterIP çš„æ–¹å¼åªèƒ½åœ¨é›†ç¾¤å†…éƒ¨è®¿é—®ã€‚
> 2.NodePort æ–¹å¼çš„è¯ï¼Œæµ‹è¯•ç¯å¢ƒä½¿ç”¨è¿˜è¡Œï¼Œå½“æœ‰å‡ åä¸Šç™¾çš„æœåŠ¡åœ¨é›†ç¾¤ä¸­è¿è¡Œæ—¶ï¼ŒNodePort çš„ç«¯å£ç®¡ç†æ˜¯ç¾éš¾ã€‚
> 3.LoadBalance æ–¹å¼å—é™äºäº‘å¹³å°ï¼Œä¸”é€šå¸¸åœ¨äº‘å¹³å°éƒ¨ç½² ELB è¿˜éœ€è¦é¢å¤–çš„è´¹ç”¨ã€‚
>
> æ‰€å¹¸ k8s è¿˜æä¾›äº†ä¸€ç§é›†ç¾¤ç»´åº¦æš´éœ²æœåŠ¡çš„æ–¹å¼ï¼Œä¹Ÿå°±æ˜¯ ingressã€‚ingress å¯ä»¥ç®€å•ç†è§£ä¸º service çš„ serviceï¼Œä»–é€šè¿‡ç‹¬ç«‹çš„ ingress å¯¹è±¡æ¥åˆ¶å®šè¯·æ±‚è½¬å‘çš„è§„åˆ™ï¼ŒæŠŠè¯·æ±‚è·¯ç”±åˆ°ä¸€ä¸ªæˆ–å¤šä¸ª service ä¸­ã€‚è¿™æ ·å°±æŠŠæœåŠ¡ä¸è¯·æ±‚è§„åˆ™è§£è€¦äº†ï¼Œå¯ä»¥ä»ä¸šåŠ¡ç»´åº¦ç»Ÿä¸€è€ƒè™‘ä¸šåŠ¡çš„æš´éœ²ï¼Œè€Œä¸ç”¨ä¸ºæ¯ä¸ª service å•ç‹¬è€ƒè™‘ã€‚
>
> ä¸¾ä¸ªä¾‹å­ï¼Œç°åœ¨é›†ç¾¤æœ‰ apiã€æ–‡ä»¶å­˜å‚¨ã€å‰ç«¯ 3 ä¸ª serviceï¼Œå¯ä»¥é€šè¿‡ä¸€ä¸ª ingress å¯¹è±¡æ¥å®ç°å›¾ä¸­çš„è¯·æ±‚è½¬å‘ï¼š

![044](images/044.png)

`ingress` è§„åˆ™æ˜¯å¾ˆçµæ´»çš„ï¼Œå¯ä»¥æ ¹æ®ä¸åŒåŸŸåã€ä¸åŒ `path` è½¬å‘è¯·æ±‚åˆ°ä¸åŒçš„ `service` ï¼Œå¹¶ä¸”æ”¯æŒ `https`/`httpã€‚`

[k8s ingress åŸç†](https://segmentfault.com/a/1190000019908991)

```yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: ingress-srv
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: posts.com
      http:
        paths:
          - path: /posts
            backend:
              serviceName: posts-clusterip-srv
              servicePort: 4000
```

- è¿™é‡Œæœ‰ `posts.com`ï¼Œå› ä¸º `vm=VirtualBox` æ‰€ä»¥åœ¨ hosts ä¿®æ”¹ posts.com åˆ° `minikube ip`

> å¤ªå±Œäº†ï¼Œç‚¸è£‚äº†ã€‚

#### Skaffold

- Automates many tasks in a k8s dev environment
- Makes it really easy to update code in a running pod
- Makes it really easy to create/delete all object tied to a project at once
- [skaffold.dev](https://skaffold.dev/)

### 05-Architecture of Multi-Service Apps

- the big challenge in microservices is data
- different ways to share data between services. We are going to focus on async communication
- async communication focuses on communication using events sent to an event bus
- async communication encourages each service to be 100% self-sufficient. Relatively easy to handle temporary downtime or new service creation
- Docker makes it easier to package up services
- K8s is a pain to setup, but makes it really to deploy + scale service

![046](images/046.png)

- We are going to make some big changes to our development process for this next project
- You might really dislike me for some of these decisions
- I wouldn't do this if i didn't think it was absolutely, positively the right way to build microservices

#### Ticketing App

- Users can list a ticket for an event (concert, sports) for sale
- Other users can purchase this ticket
- Any user can list tickets for sale and purchase tickets
- When a user attempts to purchase a ticket, the ticket is 'locked' for 15 minutes. The user has 15 minutes to enter their payment info.
- While locked, no other user can purchase the ticket. After 15 minutes, the ticket should 'unlock'
- Ticket prices can be edited if they are not locked

![047](images/047.png)

![048](images/048.png)

- We are creating a separate service to manage each type of resource
- Should we do this for every microservices app?
- Probably not? Depends on your use case, number of resources, business logic tied to each resource, etc
- Perhaps 'feature-based' design would be better

![049](images/049.png)

![050](images/050.png)

![051](images/051.png)

- `docker build -t registry.cn-shenzhen.aliyuncs.com/444/ticketing-auth .`
- `docker login`
- `docker push registry.cn-shenzhen.aliyuncs.com/444/ticketing-auth`
- `k8s-deploment`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-depl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: auth
  template:
    metadata:
      labels:
        app: auth
    spec:
      containers:
        - name: auth
          image: registry.cn-shenzhen.aliyuncs.com/444/ticketing-auth
---
apiVersion: v1
kind: Service
metadata:
  name: auth-srv
spec:
  selector:
    app: auth
  ports:
    - name: auth
      protocol: TCP
      port: 3000
      targetPort: 3000
```

> `Service` çš„é»˜è®¤ `type: ClusterIP`ï¼Œå¯ä»¥ä¸å†™ï¼ï¼ï¼

- é…ç½® `skaffold`

```yaml
apiVersion: skaffold/v2alpha3
kind: Config
deploy:
  kubectl:
    manifests:
      - ./infra/k8s/*
build:
  local:
    push: false
  artifacts:
    - image: registry.cn-shenzhen.aliyuncs.com/444/ticketing-auth
      context: auth
      docker:
        dockerfile: Dockerfile
      sync:
        manual:
          - src: 'src/**/*.ts'
            dest: .
```

![052](images/052.png)

ä¸èƒ½ä»»ç”±æŸä¸€ä¸ªæœåŠ¡ä¸ªæ€§åŒ–çš„é”™è¯¯æ ¼å¼è¿”å›ï¼Œæˆ‘ä»¬å¾—ç»Ÿä¸€é”™è¯¯è¿”å›çš„æ ¼å¼

![053](images/053.png)

å¦‚ä½•ç»Ÿä¸€é”™è¯¯å¯¹è±¡ï¼ŸæŠŠæ‰€æœ‰å·²çŸ¥åœºæ™¯å…¨éƒ¨åˆ—å‡ºæ¥ï¼Œç„¶ååˆ†æå…±åŒéœ€è¦è¾¾åˆ°çš„ç›®çš„ï¼Œæœ€åç»™å‡ºç»“æ„å³å¯ã€‚

![054](images/054.png)

![055](images/055.png)

We want an object like an 'Error', but we want to add in some more custom properties to it

> Usually a sign you want to subclass something!

![056](images/056.png)

![057](images/057.png)

> ä¸è¦åœ¨ error-middlaware ä¸­å¤„ç†ä¸šåŠ¡ï¼Œè€Œæ˜¯æŠŠä¸šåŠ¡æ”¾åœ¨å…·ä½“çš„æ¯ä¸ªé”™è¯¯ç±»é‡Œã€‚

æˆ‘ä»¬åœ¨ç»™å…¨å±€ `Error` å†å¥—ä¸€å±‚å£³å­ï¼Œè¿™ä¹Ÿæ‰€æœ‰æˆ‘ä»¬å…·ä½“ä¸šä¸»çš„é”™è¯¯ç±»å°±å¯ä»¥ç»§æ‰¿è¿™ä¸ªå£³å­ï¼Œç›®å‰æœ‰ä¸¤ä¸ªé€‰æ‹©ï¼š1.æ¥å£ å’Œ 2.æŠ½è±¡ç±»

![059](images/059.png)

![060](images/060.png)

ç°åœ¨æ—¢ç„¶æœ‰äº†è‡ªå®šä¹‰é”™è¯¯ç±»ï¼Œé‚£å¦‚ä½•æ–°å¢ä¸€ä¸ªé”™è¯¯ç±»å‘¢ï¼Ÿ

- å®šä¹‰ä¸€ä¸ªç±»ï¼Œé‡å†™æ‰€æœ‰æŠ½è±¡ç±»çš„å­—æ®µ
- æ„é€ å‡½æ•°å®šä¹‰é»˜è®¤çš„ message å­—ç¬¦ä¸²

> k8s ä¸­éƒ¨ç½² MongoDB çœŸæœ‰æ„æ€

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-mongo-depl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: auth-mongo
  template:
    metadata:
      labels:
        app: auth-mongo
    spec:
      containers:
        - name: auth-mongo
          image: mongo:4.4-bionic
          imagePullPolicy: IfNotPresent
---
apiVersion: v1
kind: Service
metadata:
  name: auth-mongo-srv
spec:
  selector:
    app: auth-mongo
  ports:
    - name: db
      protocol: TCP
      port: 27017
      targetPort: 27017
```

![060](images/061.png)

å¯¹äº†ï¼Œæ¥ä¸‹æ¥å°±æ˜¯ `mongoose` + `js` çš„è¯Ÿç—…ï¼Œæ— æ³•çŸ¥æ™“å±æ€§ç±»å‹å˜›ï¼Œæ€ä¹ˆåˆ©ç”¨ `TS` å‘¢ï¼Ÿ

```js
new User({ email: '123@123.com', password: '123123' });
```

![062](images/062.png)

![063](images/063.png)

> æˆ‘ä»¬çš„ç›®æ ‡ -> `Creating the Model with TS`

- Type checking User Properties
- Adding Static Properties to a Model

ä¸€æ®µç¾ä¸½çš„ä»£ç 

```ts
import { scrypt, randomBytes } from 'crypto';
import { promisify } from 'util';

const scryptAsync = promisify(scrypt);

export class Password {
  static async toHash(password: string) {
    const salt = randomBytes(8).toString('hex');
    const buf = (await scryptAsync(password, salt, 64)) as Buffer;

    return `${buf.toString('hex')}.${salt}`;
  }

  static async compare(storedPassword: string, suppliedPassowrd: string) {
    const [hashedPassword, salt] = storedPassword.split('.');
    const buf = (await scryptAsync(suppliedPassowrd, salt, 64)) as Buffer;

    return buf.toString('hex') === hashedPassword;
  }
}
```

### 09-Authentication Strategies and Options

![064](images/064.png)

#### Fundamenttal Options 1

![065](images/065.png)

> Individual services rely on the auth service

- æ¯ä¸ªéœ€è¦ç™»å½•ä¿¡æ¯çš„æœåŠ¡éƒ½è¦ä¾èµ– `auth` -> âŒ
- å…³é”®è¿™ä¸ªè¯·æ±‚è¿˜æ˜¯åŒæ­¥è¯·æ±‚ -> âŒ
- ä¸€æ—¦ `auth` æŒ‚äº†ï¼Œæ•´ä¸ªä¸ä¹‹ç›¸å…³çš„æ‰€æœ‰ä¸šåŠ¡éƒ½åœæ»æ— æ³•ä½¿ç”¨ï¼Œ`cluster` æŒ‚å½© -> âŒ

#### Fundamenttal Options 1.1

![066](images/066.png)

#### Fundamenttal Options 2

![067](images/067.png)

![068](images/068.png)

![070](images/070.png)

![071](images/071.png)

![072](images/072.png)

![073](images/073.png)

![074](images/074.png)

![075](images/075.png)

> åœ¨ SSR ä¸­è§£å†³é¦–æ¬¡æ¸²æŸ“é—®é¢˜çš„æ–¹æ¡ˆå°±æ˜¯ï¼Œç™»å½•æˆåŠŸæ—¶ä¸ä»…è¿”å› jwt è¿˜è¦è®¾ç½® cookies
>
> é‚£ä¹ˆå°±å¯ä»¥åœ¨æˆæƒæœŸå†…ï¼Œä½¿ç”¨ cookie ä¸­ä¸åŠ å¯†çš„ jwt å®Œæˆé¦–æ¬¡æ¸²æŸ“æ²¡æ³•è·å–ç™»å½•ä¿¡æ¯çš„é—®é¢˜

#### Securely Storing Secrets with Kubernetes

![076](images/076.png)

![077](images/077.png)

> `kubectl create secret generic jwt-secret --from-literal=JWT_KEY=1234`

```yaml
spec:
  containers:
    - name: auth
      image: registry.cn-shenzhen.aliyuncs.com/444/ticketing-auth
      env:
        - name: JWT_KEY
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: JWT_KEY
```

> è¿™é‡Œçš„ `secretKeyRef-name` å†™é”™ä¼šæœ‰æç¤ºï¼ -- `CreateContainerConfigError`ã€‚ è€Œä¸” `pod` çŠ¶æ€éƒ½ä¼šå¼‚å¸¸

![078](images/078.png)

ä¸ºäº†ç»Ÿä¸€ï¼Œæˆ‘ä»¬å¿…é¡»å°†ä¸åŒæœåŠ¡+æ•°æ®åº“çš„è¿”å›æ ¼å¼ JSON ç»Ÿä¸€ã€‚

é‚£ä¹ˆå°±æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œuser é›†åˆé‡Œçš„ passwordã€‚

```js
{
  toJSON: {
    transform(doc, ret) {
      ret.id = ret._id;
      delete ret._id;
      delete ret.password;
      delete ret.__v;
    },
  },
}
```

![079](images/079.png)

### 10 Testing Isolated Microservices

![080](images/080.png)

![081](images/081.png)

![082](images/082.png)

![083](images/083.png)

![084](images/084.png)

![085](images/085.png)

![086](images/086.png)

- `yarn add -D @types/jest @types/supertest jest ts-jest supertest mongodb-memory-server`

![087](images/087.png)

- åœ¨æµ‹è¯•ç™»å½•æ—¶ï¼Œå¯ä»¥åœ¨å…¨å±€ global æ·»åŠ ä¸€äº›æ–¹æ³•ï¼Œä¿å­˜ç™»å½• tokenï¼Œå› ä¸ºæ¯ä¸ªå‡½æ•°éƒ½æ˜¯ç‹¬ç«‹ä½œç”¨åŸŸï¼Œæ²¡æ³•å…¨å±€ä¿å­˜ä¸€ä¸ªç™»å½•ä¿¡æ¯ï¼Œé¿å…æ¯æ¬¡ç™»å½•

### 11.Integrating a Server-Side-Rendered React App

![088](images/088.png)

- We will be writing the Next app using javascript, not typescript
- It would be normally be beneficial to use TS, bug this app in particular would need a lot of extra TS stuff written out for little benefit

> è€å“¥çš„æ„æ€æ˜¯å‰ç«¯å¹¶éæœ¬è¯¾é‡ç‚¹ï¼Œè€Œä¸”ä½¿ç”¨ `TS` ä¼šå¢åŠ ä»£ç é‡ï¼Œé—´æ¥å¢åŠ å‰ç«¯è¯¾ç¨‹çš„æ—¶é—´ï¼Œæ‰€ä»¥ä¸ºäº†çªæ˜¾ç»ˆç‚¹å‰ç«¯é¡¹ç›®å°±ç”¨ `JS`

é‡è¦æç¤º

> `nextjs` åœ¨ `k8s` å’Œ `skaffold` ä¸­ç›‘å¬ä»£ç å˜åŒ–æ—¶å¿…é¡»åŠ è½½å¦‚ä¸‹é…ç½®ï¼š

```js
module.exports = {
  webpackDevMiddleware: (config) => {
    config.watchOptions.poll = 300;
    return config;
  },
};
```

![089](images/089.png)

#### ğŸ”¥ Fetching Data During SSR in Cluster

> â˜¢ï¸ ğŸŒ ğŸ¥ â­•ï¸ é‡ç‚¹æ¥äº†

```js
// æ³¨æ„è¿™é‡Œä¸èƒ½è¿™ä¹ˆç”¨ï¼
LandingPage.getInitialProps = async (context) => {
  // const res = await axios.get('/api/users');
  // ...
  // return res.data;
};
```

- ä»¥ä¸Šä»£ç å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œä¸åŒºåˆ†æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯ç¯å¢ƒï¼ŒæœåŠ¡ç«¯çš„è¯·æ±‚åœ°å€å’Œå®¢æˆ·ç«¯çš„è¯·æ±‚åœ°å€ä¸ä¸€æ ·
  - æœåŠ¡ç«¯ç”¨çš„æ˜¯ `k8s` é‡Œçš„ `clusterIP`
  - å®¢æˆ·ç«¯ç”¨çš„æ˜¯ `å¤–ç½‘åœ°å€`
  - åŒºåˆ«å¯å¤§äº† ğŸ˜‚
- æ‰€ä»¥å‘¢ï¼Œæˆ‘ä»¬åº”è¯¥æ„å»ºä¸€ä¸ªè¯·æ±‚ `request`ï¼Œè®©å®ƒçŸ¥é“è‡ªå·±æ˜¯åœ¨æœåŠ¡ç«¯ç¯å¢ƒè¿˜æ˜¯å®¢æœç«¯ç¯å¢ƒ !!!

![090](images/090.png)

![091](images/091.png)

![092](images/092.png)

![093](images/093.png)

![094](images/094.png)

![095](images/095.png)

![096](images/096.png)

> [é‡ç‚¹] We access services using that 'http://auth-srv' style only wen they are in the same namespace

- **å¼€ç€ v2ray å…¨å±€æ¨¡å¼** `k8s` çš„ `ingress` å°±å¤±æ•ˆ
- k8s é›†ç¾¤å†…éƒ¨è®¿é—®å¥—è·¯ï¼š**servicename.namespacename.svc.cluster.local**

> ä¸€ä¸ª `minikube` å‚æ•°æäº†æˆ‘ 4 ä¸ªå°æ—¶ï¼Œè¿™ä¸ª `k8s` ç®€ç›´ç©æ­»äººã€‚
>
> è¿™ä¸ªé›†ç¾¤å†…éƒ¨æˆ–è·¨å‘½åç©ºé—´è®¿é—®æ˜¯å¦‚æ­¤é‡è¦ï¼Œå¿…é¡»é¼“ç€æå‡ºæ¥ï¼Œè¦ä¸ç„¶ä¸šåŠ¡çº¿ä¼šçŸ­å•Šï¼

#### minikube ingress å¯åŠ¨ä½†æ²¡æœåŠ¡æˆ–æœåŠ¡æ²¡ 80 ç«¯å£é—®é¢˜

å…ˆçœ‹ç—‡çŠ¶ï¼š

```bash
$ k get namespaces
NAME              STATUS   AGE
default           Active   8d
kube-node-lease   Active   8d
kube-public       Active   8d
kube-system       Active   8d
```

- å¦‚ä¸Šæ‰€ç¤ºï¼Œæ²¡æœ‰å¸¸è§„çš„ `ingress-nginx` å‘½åç©ºé—´!
- å…¶å®æ˜¯éšè—åœ¨ `kube-system`

```bash
$ k get services -n kube-system
NAME                                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                   AGE
ingress-nginx-controller-admission   ClusterIP   10.101.117.241   <none>        443/TCP                   7d23h
kube-dns
```

- å“¦è±ï¼Œæœ‰ä¸ªå¾ˆåƒçš„ `service` `ingress-nginx-controller-admission`
- ä½†è€ç‹—çš„æ²¡ 80 ç«¯å£è‚¯å®šä¸å¯¹

> ğŸš€ ğŸš€ ğŸš€ ğŸš€ **è§£å†³æ–¹æ¡ˆ** ğŸš€ ğŸš€ ğŸš€ ğŸš€

- é¦–å…ˆ: `kubectl expose deployment ingress-nginx-controller --target-port=80 --type=ClusterIP -n kube-system`
  - æ²¡æœ‰å¼€ 80 å’Œ 443 çš„ `ingress-nginx-controller`ï¼Œæˆ‘æ‰‹åŠ¨åŠ ä¸€ä¸ª
- æœ€åå¯åŠ¨æ—¶ `'minikube start --vm=true'`
  - å› ä¸ºä½¿ç”¨ `docker` é©±åŠ¨æ—¶ï¼Œæˆ‘åœ¨ `MacOS` æ²¡æ³•æˆåŠŸï¼Œæ‰€ä»¥ç”¨ `virtualbox` ï¼Œæ‰€ä»¥åŠ¡å¿…åŠ ä¸Š `--vm=true` å‚æ•°
  - `minikube start --registry-mirror=https://registry.docker-cn.com --kubernetes-version=1.18.8 --driver=virtualbox --vm=true`
- æœ€åå†é‡å¤ä¸€éï¼šé›†ç¾¤å†…éƒ¨è®¿é—® service çš„å¥—è·¯æ˜¯ **servicename.namespacename.svc.cluster.local**

#### Service è§£å†³äº†ä»€ä¹ˆé—®é¢˜

![097](images/097.png)

- æˆ‘ä»¬åº”è¯¥å¦‚ä½•ä¸ºä¸€ä¸ª `Pod` å»ºç«‹ä¸€ä¸ªæŠ½è±¡ï¼Œè®©å¦ä¸€ä¸ª `Pod` æ‰¾åˆ°å®ƒå‘¢ï¼Ÿ
  - ç­”æ¡ˆï¼š`Service`
  - æ¯ä¸€ä¸ª `Service` éƒ½æ˜¯ä¸€ç»„ `Pods` çš„é€»è¾‘é›†åˆ

![098](images/098.png)

![099](images/099.png)

> ä¸Šå›¾ä»…ä¸ºé›†ç¾¤å†…è®¿é—®ç¤ºæ„å›¾ï¼

- é»˜è®¤çš„ `Service` å°±æ˜¯ `Cluster`
- `Service-A` è¦è®¿é—® `Service-hello`
- å¦‚æœåœ¨åŒä¸€å‘½åç©ºé—´ `default` çš„è¯ï¼Œç›´æ¥è®¿é—® `Service-Name` å³å¯è®¿é—®ï¼Œä¹Ÿå¯ä»¥åœ¨åé¢ç‚¹ä¸€ä¸ªå‘½åç©ºé—´
- ä¹Ÿå¯ä»¥ `hello.default.svc.cluster.local`

> æˆ‘ä¸€ç›´æœ‰ä¸ªç–‘é—®ï¼Œä¸ºå•¥å­ Pod ä¸èƒ½ç›´æ¥è¢«è®¿é—®ï¼Ÿ
>
> å› ä¸ºå¦‚æœ pod ç›´æ¥è¢«è®¿é—®ï¼Œé€»è¾‘å°±ç¼ºå¤±å¾ˆå¤šï¼ŒåŠŸèƒ½è¦†ç›–æ€§å°±è¦å°‘å¾ˆå¤šï¼ŒçœŸæ˜¯ä¸€ç‚¹æŠ½è±¡æ³„æ¼éƒ½æ²¡æœ‰ï¼

- åœ¨ k8s ä¸­ï¼ŒA è®¿é—® B æœåŠ¡ï¼Œå¦‚æœ B æœåŠ¡æ˜¯ä¸€ä¸ªè¿˜æ²¡æœ‰éƒ¨ç½²çš„æœåŠ¡ï¼Œæˆ‘ä»¬æ˜¯ä¸çŸ¥é“ B æœåŠ¡çš„ IP æˆ–è€… åŸŸå æ˜¯å¤šå°‘ã€‚
- é‚£ä¹ˆæˆ‘ä»¬åœ¨ç¼–å†™ A æœåŠ¡çš„ä»£ç æ—¶ï¼Œå¦‚ä½•æè¿° B æœåŠ¡çš„ **è®¿é—®åœ°å€** å‘¢ï¼Ÿ
- å…¶å®æˆ‘ä»¬å¯ä»¥ç»™è¿™ä¸ª B æœåŠ¡çš„è®¿é—®åœ°å€å®šä¹‰ä¸€ä¸ª **åå­—**ï¼Œå½“ B æœåŠ¡éƒ¨ç½²æ—¶ï¼Œè‡ªåŠ¨è§£æå¹¶å» DNS æ³¨å†Œè¿™ä¸ª **åå­—** å³å¯ã€‚
- è¿™å°±æ˜¯ k8 å†…éƒ¨çš„ `æœåŠ¡å‘ç°` æœºåˆ¶ï¼

```yaml
apiVersion: v1
kind: Service
metadata:
  name: hello
spec:
  selector:
    app: hello
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30080
  type: NodePort
```

![100](images/100.png)

> æˆ‘ä»¬åœ¨é›†ç¾¤é‡Œ `nextjs` åšæœåŠ¡ç«¯æ¸²æŸ“æ—¶ï¼Œè®°å¾—æŠŠ `req.headers` ä¼ é€’ä¸‹å»

![101](images/101.png)

- ä¸ºä»€ä¹ˆè¦è¿è¡Œä¸¤æ¬¡ `getInitialProps` ï¼Ÿ
- ä¸€æ¬¡åœ¨ `Custome_AppComponent` ä¸­ï¼Œä¸€æ¬¡åˆåœ¨ `IndexPage` ä¸­
- åœ¨ `IndexPage` ä¸­çš„æ¯æ¬¡åˆ·æ–°éƒ½æ‰§è¡Œ
- å…¶å®å¯ä»¥åœ¨ `Custome_AppComponent` ä¸­çš„ä½¿ä¹‹ä¼ é€’ä¸‹æ¥å³å¯

![102](images/102.png)

> æˆ‘åªèƒ½ç®¡ç†åˆ°æˆ‘å„¿å­è¾ˆçš„ï¼Œæˆ‘å¯ä»¥ä¼ ï¼Œä¹Ÿå¯ä»¥ä¸ä¼ ï¼Œæˆ‘è¿˜å¯ä»¥æ‹¿åˆ°å„¿å­è¾ˆçš„ä¸œè¥¿ã€‚

### 12 Code Sharing and Reuse Between Services

- â“ What about event-related stuff for the auth service?
- â“ It turns out that no other services really need to know about what the auth service is doing?
- â“ Everything the auth service does is exposed through that JWT in the cookie

![103](images/103.png)

js çš„ä»£ç å¤ç”¨ä¸€èˆ¬æœ‰ä¸‰ç§åŠæ³•

- #1 - Direct Copy Paste
- #2 - Git Submodule
- #3 - NPM Package (ä¹Ÿå¯ä»¥è‡ªå·±æ­ç§æœ)

- There might be differences in out TS settings between the common lib and our services - don't want to deal with that
- Service might not be written with TS at all!
- Our common library will be written Typescript and published as Javascript

- åœ¨å•ç‹¬ä½¿ç”¨å…±äº«åº“æ—¶ï¼Œæ›´æ–°åº“ä½¿ç”¨ `npm update @js-ticketing/common`
- å‘å¸ƒäº†æ–°çš„ common åº“ï¼Œæœ€å¥½å»å…³è” pod æˆ–å®¹å™¨å†…çœ‹çœ‹æ˜¯å¦ç”¨ä¸Šäº†æœ€æ–°çš„åº“

### 13 Create-Read-Update-Destroy Server Setup

Ticketing Service Overview

![104](images/104.png)

```ts
const start = async () => {
  if (!process.env.JWT_KEY) {
    throw new Error('JWT_KEY must be defined');
  }

  if (!process.env.MONGO_URI) {
    throw new Error('MONGO_URI must be defined');
  }

  try {
    await mongoose.connect(process.env.MONGO_URI, {
      useNewUrlParser: true,
      useUnifiedTopology: true,
      useCreateIndex: true
    });
    console.log('Connected to MongoDb');
  } catch (err) {
    console.error(err);
  }

  app.listen(3000, () => {
    console.log('Listening on port 3000!!!!!!!!');
  });
};
```

#### æ„Ÿæ‚Ÿ

> <span style="color: #e74c3c;font-size: 18px">å¥½ä»£ç  -> å‡ ä¹ä¸€æ ·</span>
>
> <span style="color: #e74c3c;font-size: 18px">çƒ‚ä»£ç  -> åƒå¥‡ç™¾æ€ª</span>

åŸæ¥å¬åˆ°è¿™å¥è¯ï¼Œå½“æ—¶ä¸æ˜¯å¾ˆç†è§£ï¼Œç°åœ¨çœŸçš„è¢«æ„Ÿè§‰å‡ºæ¥äº†ï¼š

- ä¸€ä¸ªä¸¤å¹´å‰çš„ä»£ç ï¼Œç¾å›½äººå†™çš„
- ä¸€ä¸ªä¸€å¹´å‰çš„ä»£ç ï¼Œä¿„ç½—æ–¯äººå†™çš„
- ä¸€ä¸ªæœ€è¿‘ä¸€å‘¨çš„ä»£ç ï¼Œå°åº¦äººå†™çš„

> <span style="color: #e74c3c;font-size: 17px">å‡ ä¹ä¸€æ ·ï¼</span>

#### æµ‹è¯•å…ˆè¡Œ

![105](images/105.png)

- æˆ‘ä»¬è¦å†™ä¸€ä¸ªä¸šåŠ¡ï¼Œæ¡†æ¶å·²æ­å»ºå¥½ï¼Œåªéœ€è¦ä»æµé‡å…¥å£å¼€å§‹å†™ï¼Œé‚£äº›æ˜¯ `controller`
- å› ä¸ºå†™å…¥å·²ç»å¾ˆæ˜ç¡®ï¼Œçœ‹ä¸Šå›¾æ‰€ä»¥å¯ä»¥å…ˆå†™æµ‹è¯•ç”¨ä¾‹

```ts
import request from 'supertest';
import { app } from '../../app';

it('has a route handler listening to /api/tickets for post requests', async () => {});

it('can only be accessed if the user is signed in', async () => {});

it('returns an error if an invalid title is provided', async () => {});

it('returns an error if an invalid price is provided', async () => {});

it('creates a ticket with valid inputs', async () => {});

// npm run test // -> æµ‹è¯•èµ°èµ·
```

![106](images/106.png)

![107](images/107.png)

### 14 NATS Streaming Server

![108](images/108.png)

![109](images/109.png)

![110](images/110.png)

#### NATS Streaming

- docs.nats.io
- NATS and NATS Streaming Server are two different things
- NATS Streaming implements some extraordinarily important design decisions that will affect our app
- We are going to run the official `nats-streaming` docker image in k8s. Need to read the image's docs.

```yaml
containers:
  - name: nats
    image: nats-streaming:0.17.0
    args:
      [
        '-p',
        '4222',
        '-m',
        '8222',
        '-hbi',
        '5s',
        '-hbt',
        '5s',
        '-hbf',
        '2',
        '-SD',
        '-cid',
        'ticketing',
      ]
```

- -cid, --cluster_id  `<string>`         Cluster ID (default: test-cluster)
- -hbi, --hb_interval `<duration>`       Interval at which server sends heartbeat to a client
- -hbt, --hb_timeout `<duration>`        How long server waits for a heartbeat response
- -hbf, --hb_fail_count `<int>`          Number of failed heartbeats before server closes the client connection
- -SD, --stan_debug=`<bool>`             Enable STAN debugging output

#### Big Notes on NATS Streaming

![111](images/111.png)

![112](images/112.png)

![113](images/113.png)

![114](images/114.png)

![115](images/115.png)

![116](images/116.png)

- `k port-forward nats-depl-8674c9d8b-z7qgc 4222:4222`

```json
"scripts": {
  "publish": "ts-node-dev --rs --notify false src/publisher.ts",
  "listen": "ts-node-dev --rs --notify false src/listener.ts"
},
```

#### Client ID Generation

- `NATS` æ˜¯ä¸å…è®¸ä¸¤ä¸ªç›¸åŒ `ClientID` çš„å­˜åœ¨ âŒ
- æ‰€ä»¥ listener çš„ID `randomBytes(4).toString('hex')`

### Queue Groups

> é˜Ÿåˆ—åˆ†ç»„

![117](images/117.png)

![118](images/118.png)

- åªç»™åˆ†ç»„é‡Œçš„ä¸€ä¸ª Listener å‘é€
- æ²¡åˆ†ç»„ï¼Œä½†åˆç›‘å¬é‚£ä¸ªé¢‘é“çš„æ‰€æœ‰ Listener éƒ½ä¼šæ”¶åˆ°
- NATS å°±æ˜¯å¦‚æ­¤ä¹‹ç®€å•

```ts
  const subscription = stan.subscribe('ticket:created', 'orders-service-queue-group');
```

#### Manual Ack Mode

> æ‰‹åŠ¨ç¡®è®¤æ”¶åˆ°æ¨¡å¼

```ts
const options = stan.subscriptionOptions().setManualAckMode(true);

const subscription = stan.subscribe(
  'ticket:created',
  'orders-service-queue-group',
  options
);
```

![119](images/119.png)

#### Client Health Checks

æ˜¯æ—¶å€™çœ‹æˆ‘ä»¬çš„ `NATS-Streaming` äº†

- `http://localhost:8222/`
- `http://localhost:8222/streaming`
  - server - æœåŠ¡ç«¯çŠ¶æ€
  - store
  - clients: å¤šå°‘ä¸ªå®¢æˆ·ç«¯å’Œå…¶ç»Ÿè®¡
  - channels
  - `http://localhost:8222/streaming/channelsz`
  - `http://localhost:8222/streaming/channelsz?subs=1`

```json
{
  "cluster_id": "ticketing",
  "server_id": "g4fLu1bOVnS8CHONPcBJ9R",
  "now": "2021-08-28T06:52:48.594224213Z",
  "offset": 0,
  "limit": 1024,
  "count": 1,
  "total": 1,
  "channels": [
    {
      "name": "ticket:created",
      "msgs": 4,
      "bytes": 284,
      "first_seq": 1,
      "last_seq": 4,
      "subscriptions": [
        {
          "client_id": "2ae3ce9f",
          "inbox": "_INBOX.4HBRWIQAJ18FLBJW61DXM6",
          "ack_inbox": "_INBOX.g4fLu1bOVnS8CHONPcBJUr",
          "queue_name": "orders-service-queue-group",
          "is_durable": false,
          "is_offline": false,
          "max_inflight": 16384,
          "ack_wait": 30,
          "last_sent": 3,
          "pending_count": 0,
          "is_stalled": false
        },
        {
          "client_id": "8fa5936d",
          "inbox": "_INBOX.NOW3ZZ2LSD2WI92T2VIA7K",
          "ack_inbox": "_INBOX.g4fLu1bOVnS8CHONPcBJaD",
          "queue_name": "orders-service-queue-group",
          "is_durable": false,
          "is_offline": false,
          "max_inflight": 16384,
          "ack_wait": 30,
          "last_sent": 4,
          "pending_count": 0,
          "is_stalled": false
        }
      ]
    }
  ]
}
```

#### Graceful Client Shutdown

```ts
stan.on('close', () => {
  console.log('NATS connection closed!');
  process.exit();
})

process.on('SIGINT', () => stan.close());
process.on('SIGNTERM', () => stan.close());
```

- ğŸ“¢ æ³¨æ„ï¼šåªæœ‰åšäº†ä¼˜é›…çš„é€€å‡ºï¼ŒæœåŠ¡ç«¯çš„ `clients` æ•°é‡æ‰æ˜¯æ­£å¸¸çš„ï¼Œè¦ä¸ç„¶è¿˜è¦éº»çƒ¦ â€œåˆ«äººâ€ã€‚

#### Core Concurrency Issues

> å…³é”®å¹¶å‘é—®é¢˜

![120](images/120.png)

![121](images/121.png)

![122](images/122.png)

#### Solving Concurrency Issues

- We are working with a poorly designed system and relying on NATS to somehow save us
- We should revisit the service design
- If we redesign the system, a better solution to this concurrency stuff will present itself

> çœŸæœŸå¾… ğŸ¤”
>
> æ˜¯çš„ï¼Œæˆ‘ä»¬åº”è¯¥å›å¤´çœ‹çœ‹æˆ‘ä»¬çš„ `mini-posts` æˆ–è®¸å¯ä»¥ç»™æˆ‘ä»¬ä»€ä¹ˆè§£å†³çµæ„Ÿ

![123](images/123.png)

#### å› åˆ†å¸ƒå¼ç³»ç»ŸåŸå› ï¼Œå¾…æˆ‘ä»¬è§£å†³çš„é—®é¢˜

- æŸä¸€ç»„ `Services` é›†ç¾¤é‡Œçš„æŸä¸€ä¸ª `Service` å‰¯æœ¬åœ¨å¤„ç†ä¸šåŠ¡æ˜¯ä¼š **å¤±è´¥** âŒ
- æŸä¸€ä¸ª `Service` å‰¯æœ¬ä¸€ä¸å°å¿ƒä¼šæ¯”å…¶ä»–å‰¯æœ¬è¿è¡Œçš„å¿« ğŸš€
- NATS æ¶ˆæ¯æ€»çº¿ä»¥ä¸ºæŸä¸ªå·²ç» `æŒ‚å½©` çš„ `Service` å‰¯æœ¬è¿˜æ´»ç€ ğŸ’€
- `Services` é›†ç¾¤é‡Œçš„å‰¯æœ¬æœ‰å¯èƒ½æ¥å£é‡å¤çš„æ¶ˆæ¯ ğŸŒ ğŸŒ

> æ˜¯æ—¶å€™è§£å†³ä»¥ä¸Šè¿™äº›è€è¡¨äº†ï¼ğŸ‘º

#### Concurrency Control with the Tickets App

> TODO

### 15 Connecting to NATS in a Node JS World

![124](images/124.png)

![125](images/125.png)

The Listener Abstract Class -> ğŸ‘ğŸ»

> ä»£ç çš„ä¼˜ç¾

```ts
abstract class Listener {
  private client: Stan;
  abstract subject: string;
  abstract queueGroupName: string;

  abstract onMessage(data: any, msg: Message): void;

  protected ackWait = 5 * 1000;

  constructor(client: Stan) {
    this.client = client;
  }

  subscriptionOptions() {
    return this.client
      .subscriptionOptions()
      .setManualAckMode(true)
      .setDeliverAllAvailable()
      .setAckWait(this.ackWait)
      .setDurableName(this.queueGroupName);
  }

  listen() {
    const subscription = this.client.subscribe(
      this.subject,
      this.queueGroupName,
      this.subscriptionOptions()
    );

    subscription.on('message', (msg: Message) => {
      console.log(`Message received: ${this.subject} / ${this.queueGroupName}`);

      const patsedData = this.parseMessage(msg);

      this.onMessage(patsedData, msg);
    });
  }

  parseMessage(msg: Message) {
    const data = msg.getData();
    return typeof data === 'string'
      ? JSON.parse(data)
      : JSON.parse(data.toString('utf8'));
  }
}
```

![125](images/125.png)

- æˆ‘ä»¬åº”è¯¥æŠŠæŠ½è±¡ä¸å®ç°åˆ†ç¦»
- æ¯•ç«Ÿè¿™ä¸ªæ˜¯ä¸ªå¾®æœåŠ¡é¡¹ç›®ï¼Œæ‰€ä»¥æŠŠ `Class Listener` æ”¾åˆ°å…¬å…±ä»£ç ï¼Œå®ƒçš„å®ç°å°±æ•£å¸ƒåœ¨å®é™… `Service` ä¸­å³å¯

![126](images/126.png)

![127](images/127.png)

![128](images/128.png)

æ¶ˆæ¯åœ¨é€šä¿¡è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åº”è¯¥æŠŠ subject ç”¨æšä¸¾å›ºå®šä¸‹æ¥ï¼Œåƒä¸‡ä¸èƒ½ç”¨å­—ç¬¦ä¸²ï¼Œå› ä¸ºå…¶ä¸å¯æ§ï¼Œå¯¼è‡´dataæ ¼å¼é”™ä¹±ï¼Œè¿˜ä¼šå¼•èµ·ç©ºæŒ‡é’ˆã€‚

![129](images/129.png)

ä»£ç æ­£ç¡®çš„ç»„ç»‡æ–¹å¼ï¼

> ä¸ºäº†é¢„é˜² `publisher` æ˜å¤´æ‚è„‘çš„å‘äº›æ•°æ®ï¼Œå¿…é¡»é‡æ„ã€‚

![130](images/130.png)

![131](images/131.png)

![132](images/132.png)

å€Ÿé‰´ä¸‹ `mongoose`ï¼Œæˆ‘ä»¬å¼€ä¸ªå•ä¾‹

![133](images/133.png)

![134](images/134.png)

#### test ticket-created-publisher

- `skaffold dev`
- `k get pods`
  - nats-deploment æ­£å¸¸
  - æŠŠå®ƒçš„ `4222` æ‰‹åŠ¨æµ‹è¯•æ˜ å°„å‡ºæ¥
  - `k port-forward nats-depl-69b65fd545-xkcfk 4222:4222`
- ä½¿ç”¨ `nats-test` é‡Œçš„ `listener` ç›‘å¬å¯¹åº” `channel`
- `rest-api` æ¥å£æ‰‹åŠ¨å‘åŒ…ï¼Œåˆ›å»º `ticket` ï¼Œçœ‹ `listener` æ˜¯å¦æ­£å¸¸

```bash
NAME                                  READY   STATUS    RESTARTS   AGE
auth-depl-58d65454dc-vmggt            1/1     Running   0          70m
auth-mongo-depl-6cd58b78fb-9cp6v      1/1     Running   0          70m
client-depl-cfd877c6f-v57ld           1/1     Running   0          70m
nats-depl-69b65fd545-xkcfk            1/1     Running   0          70m
tickets-depl-f6b454654-69ftg          1/1     Running   0          70m
tickets-mongo-depl-8448df7874-5kp5k   1/1     Running   0          70m
```

![135](images/135.png)

> **éå¸¸å®Œç¾**
>
> äº›è®¸æ„Ÿæ‚Ÿï¼šè·ä»Š(2021-09-01)åå…­ä¸ªæœˆå‰æ‹¿åˆ°æ•™ç¨‹ï¼Œæ²¡æœ‰å¥½å¥½çæƒœï¼Œç›´åˆ°å¿«ä¸€å¹´åŠåæ‰å¹¡ç„¶é†’æ‚Ÿï¼Œ600å¤šé›†æ•™ç¨‹è·Ÿåˆ°330é›†ï¼Œæ”¶è·å®åœ¨å¤ªå¤§ï¼ŒåšæŒæ‰ä¼šæœ‰è´¨å˜å•Šï¼
>
> è·³å‡ºèˆ’é€‚åŒºï¼Œç—›å¹¶å¿«ä¹ï¼
>
> è¿˜æœ‰å°±æ˜¯è®¤å‡†ä¸€ä¸ªä¸œè¥¿æ˜¯å¥½çš„ï¼Œå°±è¦ä¸€å£ä¸å‰©çš„å…¨éƒ¨åƒå®Œï¼ğŸ˜ˆ ğŸ˜ˆ ğŸ˜ˆ

#### ä¿®å¤ä¸€ä¸ªæµ‹è¯•é—®é¢˜

![136](images/136.png)

![137](images/137.png)

![138](images/138.png)

![139](images/139.png)

> æµ‹è¯•ç¯å¢ƒæˆ‘ä»¬æ²¡æœ‰ `natsWrapper`

```ts
import request from 'supertest';
import { app } from '../../app';
import { Ticket } from '../../models/ticket';

// å¯ä»¥å•ç‹¬æ–‡ä»¶æŒ‡å®šï¼Œæœ€å¥½åœ¨æ€»çš„æ–‡ä»¶ setup.ts ä¸­æŒ‡å®š
jest.mock('../../nats-wrapper');

it('has a route handler listening to /api/tickets for post requests', async () => {
  const response = await request(app).post('/api/tickets').send({});

  expect(response.status).not.toEqual(404);
});
```

```ts
export const natsWrapper = {
  client: {
    publish: (subject: string, data: string, callback: () => void) => {
      callback();
    }
  }
}
// -------
export const natsWrapper = {
  client: {
    publish: jest
      .fn()
      .mockImplementation(
        (subject: string, data: string, callback: () => void) => {
          callback();
        }
      ),
  },
};
```

- åœ¨ä½¿ç”¨æ¶ˆæ¯ç³»ç»Ÿæ—¶ï¼Œä¸ºäº†ç¡®ä¿æ¶ˆæ¯å‘é€æ­£å¸¸ï¼Œå¿…é¡»ç”¨ jest åšä¸€ä¸ªæµ‹è¯•ï¼Œä¿è¯äº‹ä»¶æ¶ˆæ¯ä¸€å®šè¢«å‘å‡ºï¼

### 17 Cross-Service Data Replication In Action

![140](images/140.png)

![141](images/141.png)

- åªå¤åˆ¶é™¤äº† `node_modules` å’Œ `src` ä»¥å¤–çš„æ”¯æ’‘æ–‡ä»¶
- `docker build -t registry.cn-shenzhen.aliyuncs.com/444/ticketing-orders .`

![142](images/142.png)

ä¸€ä¸ªæ¶ˆæ¯å‘é€çš„æŠ€å·§

- å› ä¸ºç›®å‰ä¸¤ä¸ªæœåŠ¡ä¹‹é—´æ¶ˆæ¯é€šä¿¡ï¼Œå¦‚æœAæœåŠ¡å‘ç»™BæœåŠ¡ï¼Œè™½ç„¶Aè§‰å¾—å‘æˆåŠŸäº†ï¼Œè¯¥æœ‰çš„éƒ½æœ‰ï¼Œä½†ä¾‹å¦‚ticketIdä¸æ˜¯åˆæ³•çš„ï¼ŒBæ”¶åˆ°ç¼ºæ— æ³•è¿›è¡Œä¸šåŠ¡ï¼Œè¿™æ ·å°±ä¼šå‡ºç°åˆ†å¸ƒå¼äº‹åŠ¡é—®é¢˜
- æ‰€ä»¥ä¸ºäº†å°½å¯èƒ½å‡å°‘è¿™æ ·è·¨æœåŠ¡ä¹‹é—´çš„äº‹åŠ¡è€¦åˆï¼Œ`å‘å¡å¼¯çš„è¿ç¯è½¦ç¥¸`é—®é¢˜ï¼Œæˆ‘ä»¬å› ç«Ÿå¯èƒ½åœ¨å‘å‡ºæ—¶å°±åšå¥½è‡ªæˆ‘éªŒè¯
- **å‡å°‘å‡ºäº‹çš„æ¦‚ç‡ï¼Œè‡ªæˆ‘è®¤çœŸæ£€æŸ¥**

```ts
router.post(
  '/api/orders',
  requireAuth,
  [
    body('ticketId')
      .not()
      .isEmpty()
      .custom((input: string) => mongoose.Types.ObjectId.isValid(input))
      .withMessage('TicketId must be provided'),
  ],
  validateRequest,
  async (_: Request, res: Response) => {
    res.send({});
  }
);
```

#### ä¸¤ä¸ªæœåŠ¡æ•°æ®å‰¯æœ¬

![143](images/143.png)

---

### 18 Understanding Event Flow

![144](images/144.png)

![145](images/145.png)

### 19 Listening for Events and Handling Concurrency Issues

![146](images/146.png)

![147](images/147.png)

![148](images/148.png)

- åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿäº†ï¼Œæœ€å•°å—¦çš„å°±æ˜¯è¿™ä¸ªæ•°æ®ä¸€è‡´æ€§é—®é¢˜
- `Tickets-Service` æœ‰ä¸€ä¸ªåŸç”Ÿçš„ `ticket` å®ä½“ï¼Œé€šè¿‡ `Message` ä¼ åˆ°äº† `Orders-Service`
- `Orders-Service` æ¥åˆ°äº†è¿™ä¸ªæ¶ˆæ¯ï¼ŒæŠŠ `ticket` å®ä½“ä¿å­˜ä¸‹æ¥ï¼Œé‚£ä¹ˆä»·æ ¼ `price` æœ‰ä¸¤ä»½ï¼Œå”¯ä¸€æ ‡è¯† `_id` æœ‰ä¸¤ä»½ï¼Œéå¸¸éº»çƒ¦ï¼
- æœ€ç»ˆæˆ‘ä»¬çš„åœ¨ `Orders-Service` è°ƒæ•´ `ID` äº†ï¼Œä¹Ÿå°±æ˜¯ä» source èµ·æºåœ°å¼€å§‹ï¼ŒæŠŠå”¯ä¸€æ ‡è¯†ç¬¦å…¨éƒ¨åŒæ­¥ä¸€è‡´

#### æµ‹è¯• orders å’Œ tickets ä¹‹é—´çš„é€šä¿¡

```bash
[tickets] Event published to subject ticket:created
[orders] Message received: ticket:created / orders-service
[tickets] Event published to subject ticket:created
[orders] Message received: ticket:created / orders-service
[orders] Message received: ticket:created / orders-service
[tickets] Event published to subject ticket:created
[tickets] Event published to subject ticket:created
[orders] Message received: ticket:created / orders-service
[tickets] Event published to subject ticket:updated
[orders] Message received: ticket:updated / orders-service
```

> ä¹Ÿæ˜¯é†‰äº†ï¼Œç«Ÿç„¶æ”¶åˆ°åœ¨å‘é€ä¹‹å‰ï¼
>
> å¤ªå±Œäº†ï¼Œç«Ÿç„¶åŒæ­¥äº†ï¼

### Docker

Why use Docker ?

> Docker makes it really easy to install and run software without worrying about setup or dependencies.

![d001](images/docker/d001.png)

![d002](images/docker/d002.png)

![d004](images/docker/d004.png)

![d005](images/docker/d005.png)

![d006](images/docker/d006.png)

![d007](images/docker/d007.png)

![d008](images/docker/d008.png)
